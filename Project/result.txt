
================================
Recognizing hand-written letters
================================

An example showing how scikit-learn can be used to recognize images of
hand-written digits.

Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False):
             precision    recall  f1-score   support

a        1.0       1.00      0.49      0.66      3396
b        2.0       1.00      0.49      0.65      3396
c        3.0       1.00      0.50      0.67      3419
d        4.0       1.00      0.50      0.67      3398
e        5.0       1.00      0.50      0.67      3437
f        6.0       1.00      0.50      0.67      3394
g        7.0       1.00      0.50      0.67      3385
h        8.0       1.00      0.50      0.66      3424
i        9.0       1.00      0.49      0.65      3428
j       10.0       1.00      0.51      0.68      3402
k       11.0       1.00      0.49      0.66      3438
l       12.0       1.00      0.51      0.67      3415
m       13.0       1.00      0.51      0.68      3402
n       14.0       1.00      0.51      0.67      3365
o       15.0       1.00      0.49      0.65      3408
p       16.0       1.00      0.50      0.67      3430
q       17.0       1.00      0.49      0.66      3435
r       18.0       1.00      0.50      0.67      3419
s       19.0       1.00      0.50      0.67      3392
t       20.0       1.00      0.50      0.67      3436
u       21.0       0.07      1.00      0.14      3419
v       22.0       1.00      0.51      0.68      3422
w       23.0       1.00      0.50      0.67      3423
x       24.0       1.00      0.51      0.67      3437
y       25.0       1.00      0.49      0.66      3453
z       26.0       1.00      0.49      0.66      3427

avg / total       0.96      0.52      0.65     88800


Confusion matrix:
[[1676    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1720    0    0    0    0    0]
 [   0 1653    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1743    0    0    0    0    0]
 [   0    0 1716    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1703    0    0    0    0    0]
 [   0    0    0 1709    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1689    0    0    0    0    0]
 [   0    0    0    0 1722    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1715    0    0    0    0    0]
 [   0    0    0    0    0 1694    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1700    0    0    0    0    0]
 [   0    0    0    0    0    0 1698    0    0    0    0    0    0    0     0    0    0    0    0    0 1687    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1699    0    0    0    0    0    0     0    0    0    0    0    0 1725    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1668    0    0    0    0    0     0    0    0    0    0    0 1760    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0 1751    0    0    0    0     0    0    0    0    0    0 1651    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0 1687    0    0    0     0    0    0    0    0    0 1751    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0 1730    0    0     0    0    0    0    0    0 1685    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0 1746    0     0    0    0    0    0    0 1656    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0 1702     0    0    0    0    0    0 1663    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0  1657    0    0    0    0    0 1751    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0 1724    0    0    0    0 1706    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0 1688    0    0    0 1747    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0 1716    0    0 1703    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0 1708    0 1684    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0 1712 1724    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 3419    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1677 1745    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1705    0 1718    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1695    0    0 1742    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1768    0    0    0 1685    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1756    0    0    0    0 1671]]
 
 
 test2
 Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False):
             precision    recall  f1-score   support

        1.0       1.00      0.49      0.66      3396
        2.0       1.00      0.49      0.65      3396
        3.0       1.00      0.50      0.67      3419
        4.0       1.00      0.50      0.67      3398
        5.0       1.00      0.50      0.67      3437
        6.0       1.00      0.50      0.67      3394
        7.0       1.00      0.50      0.67      3385
        8.0       1.00      0.50      0.66      3424
        9.0       1.00      0.49      0.65      3428
       10.0       1.00      0.51      0.68      3402
       11.0       1.00      0.49      0.66      3438
       12.0       1.00      0.51      0.67      3415
       13.0       1.00      0.51      0.68      3402
       14.0       1.00      0.51      0.67      3365
       15.0       1.00      0.49      0.65      3408
       16.0       1.00      0.50      0.67      3430
       17.0       1.00      0.49      0.66      3435
       18.0       1.00      0.50      0.67      3419
       19.0       1.00      0.50      0.67      3392
       20.0       1.00      0.50      0.67      3436
       21.0       0.07      1.00      0.14      3419
       22.0       1.00      0.51      0.68      3422
       23.0       1.00      0.50      0.67      3423
       24.0       1.00      0.51      0.67      3437
       25.0       1.00      0.49      0.66      3453
       26.0       1.00      0.49      0.66      3427

avg / total       0.96      0.52      0.65     88800


Confusion matrix:
[[1676    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1720    0    0    0    0    0]
 [   0 1653    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1743    0    0    0    0    0]
 [   0    0 1716    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1703    0    0    0    0    0]
 [   0    0    0 1709    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1689    0    0    0    0    0]
 [   0    0    0    0 1722    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1715    0    0    0    0    0]
 [   0    0    0    0    0 1694    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1700    0    0    0    0    0]
 [   0    0    0    0    0    0 1698    0    0    0    0    0    0    0     0    0    0    0    0    0 1687    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1699    0    0    0    0    0    0     0    0    0    0    0    0 1725    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1668    0    0    0    0    0     0    0    0    0    0    0 1760    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0 1751    0    0    0    0     0    0    0    0    0    0 1651    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0 1687    0    0    0     0    0    0    0    0    0 1751    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0 1730    0    0     0    0    0    0    0    0 1685    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0 1746    0     0    0    0    0    0    0 1656    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0 1702     0    0    0    0    0    0 1663    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0  1657    0    0    0    0    0 1751    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0 1724    0    0    0    0 1706    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0 1688    0    0    0 1747    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0 1716    0    0 1703    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0 1708    0 1684    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0 1712 1724    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 3419    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1677 1745    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1705    0 1718    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1695    0    0 1742    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1768    0    0    0 1685    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 1756    0    0    0    0 1671]]

test3: replaced [:size \\ 2] with [:size \\ 1]
Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False):
             precision    recall  f1-score   support

        1.0       1.00      1.00      1.00      3396
        2.0       1.00      1.00      1.00      3396
        3.0       1.00      1.00      1.00      3419
        4.0       1.00      1.00      1.00      3398
        5.0       1.00      1.00      1.00      3437
        6.0       1.00      1.00      1.00      3394
        7.0       1.00      1.00      1.00      3385
        8.0       1.00      1.00      1.00      3424
        9.0       1.00      1.00      1.00      3428
       10.0       1.00      1.00      1.00      3402
       11.0       1.00      1.00      1.00      3438
       12.0       1.00      1.00      1.00      3415
       13.0       1.00      1.00      1.00      3402
       14.0       1.00      1.00      1.00      3365
       15.0       1.00      1.00      1.00      3408
       16.0       1.00      1.00      1.00      3430
       17.0       1.00      1.00      1.00      3435
       18.0       1.00      1.00      1.00      3419
       19.0       1.00      1.00      1.00      3392
       20.0       1.00      1.00      1.00      3436
       21.0       1.00      1.00      1.00      3419
       22.0       1.00      1.00      1.00      3422
       23.0       1.00      1.00      1.00      3423
       24.0       1.00      1.00      1.00      3437
       25.0       1.00      1.00      1.00      3453
       26.0       1.00      1.00      1.00      3427

avg / total       1.00      1.00      1.00     88800


Confusion matrix:
[[3396    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0 3396    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0 3419    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0 3398    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0 3437    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0 3394    0    0    0    0    0    0    0    0     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0 3385    0    0    0    0    0    0    0     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 3424    0    0    0    0    0    0     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 3428    0    0    0    0    0     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0 3402    0    0    0    0     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0 3438    0    0    0     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0 3415    0    0     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0 3402    0     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0 3365     0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0  3408    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0 3430    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0 3435    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0 3419    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0 3392    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0 3436    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0 3419    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0    0 3422    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0    0    0 3423    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0    0    0    0 3437    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0    0    0    0    0 3453    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0    0    0    0    0    0    0    0    0    0 3427]]

